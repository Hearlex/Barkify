{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b863990e",
   "metadata": {},
   "source": [
    "# Barkify: an unoffical repo for training 'bark' like generative model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a97cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import random\n",
    "from IPython.display import Audio\n",
    "import IPython.display as iply\n",
    "\n",
    "from pqdm.processes import pqdm\n",
    "from pqdm.threads import pqdm as pqdmT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "start_path = \"../work_env\"\n",
    "start_path += '/'\n",
    "\n",
    "cuda_devices = [0,1,2,3]*3\n",
    "NJOB = len(cuda_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiprocess(x):\n",
    "    DEVICE, IJOB = x\n",
    "    subprocess.call(f\"CUDA_VISIBLE_DEVICES={DEVICE} \"+\n",
    "                   f\"nohup python {os.path.join(start_path, 'tmp', 'temp.py')} {IJOB} \"+\n",
    "                   f\"> {os.path.join(start_path, 'tmp','tmp_'+str(IJOB))} 2>&1\",\n",
    "                   shell=True)\n",
    "    \n",
    "def write_tmp(_script):\n",
    "    with open(os.path.join(start_path, \"tmp\", \"temp.py\"), \"w\") as f:\n",
    "        f.write(_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all wav to /raw/ folder\n",
    "os.makedirs(start_path + \"wavs\", exist_ok=True)\n",
    "\n",
    "def run(x):\n",
    "    # \n",
    "    name = x.replace(\"/raw/\",\"/wavs/\")\n",
    "    return subprocess.run(f\"ffmpeg -hide_banner -loglevel panic -y -i '{x}' -ac 1 -ar 24000 {name}\",\n",
    "                   shell=True)\n",
    "wavs_name = glob(os.path.join(start_path, \"raw/*.wav\"))\n",
    "res = pqdm(wavs_name, run, n_jobs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d74e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(start_path + \"wavs16k\", exist_ok=True)\n",
    "\n",
    "def run(x):\n",
    "    # \n",
    "    name = x.replace(\"/raw/\",\"/wavs16k/\")\n",
    "    return subprocess.run(f\"ffmpeg -hide_banner -loglevel panic -y -i '{x}' -ac 1 -ar 16000 {name}\",\n",
    "                   shell=True)\n",
    "wavs_name = glob(os.path.join(start_path, \"raw/*.wav\"))\n",
    "res = pqdm(wavs_name, run, n_jobs=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acacc46",
   "metadata": {},
   "source": [
    "## Fetch features from wav2vec2-xlsr and encodec\n",
    "根据[meta的论文](https://arxiv.org/pdf/2105.11084.pdf),w2v中15-18层都取得了不错的结果.<br>\n",
    "在我们的实验中证实,w2v2-xlsr中第15层与bark的semantic idx的相关性最高.\n",
    "\n",
    "在[audioLM](https://arxiv.org/pdf/2209.03143.pdf)中,使用了w2v-bert的7层作为特征.在w2v中,相关性也非常高.<br>\n",
    "我们使用第15层作为实验的特征层.\n",
    "\n",
    "另外,我们测试了bark代码中,coarse2fine的部分.我们发现,coarse和fine均从encodec中直接得到.<br>\n",
    "因此,如果没有特殊需求,不建议重新训练.\n",
    "\n",
    "1. Fetch w2v2 hiddens.\n",
    "2. Cluster them by codes from fairseq.\n",
    "3. Dump cluster idxs to numpy files.\n",
    "4. Fetch discrete indices from encodec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER = 15 # use 15th layer.\n",
    "Hubert = False # use hubert feature or use w2v2-xlsr feature\n",
    "\n",
    "clusters = 2048 # semantic idx nums.\n",
    "dtype = 32 if clusters > 65535 else 16\n",
    "\n",
    "percent = 0.1 # use 10% datas for clustering. \n",
    "n_init = 10 # when this is larger than 10, some error may occur.\n",
    "\n",
    "params = dict( # params for clusting. \n",
    "        init='k-means++', max_iter=100, batch_size=10000, \n",
    "        tol=0, max_no_improvement=100, n_init=n_init, reassignment_ratio=0,\n",
    "        compute_labels=False, verbose=100\n",
    "    )\n",
    "params['n_clusters'] = clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a7c36",
   "metadata": {},
   "source": [
    "### Fetch semantic hiddens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b61553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process hubert/w2v2 data such that the Hz of semantic idx equals to 50 rather than 49.9\n",
    "def process_audio(path):\n",
    "    wav, fs = sf.read(path)\n",
    "    safe_length = (wav.shape[0] // 640) * 640 + 160\n",
    "    wav = wav[:safe_length]\n",
    "    wav = np.pad(wav, (safe_length - wav.shape[0], 0))\n",
    "    sf.write(path, wav, fs)\n",
    "    \n",
    "wavs_name = glob(start_path + \"/wavs16k/*.wav\")\n",
    "res = pqdmT(wavs_name, process_audio, n_jobs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(start_path + \"tmp\", exist_ok=True)\n",
    "os.makedirs(start_path + \"feats\", exist_ok=True)\n",
    "\n",
    "_script =f'''\n",
    "from transformers import AutoProcessor, AutoModelForPreTraining, AutoModel\n",
    "if {Hubert}:\n",
    "    model = AutoModel.from_pretrained(\"TencentGameMate/chinese-hubert-large\")\n",
    "else:\n",
    "    model = AutoModelForPreTraining.from_pretrained(\"facebook/wav2vec2-large-xlsr-53\")\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "print(\"downloaded!\")\n",
    "'''\n",
    "write_tmp(_script) # download it.\n",
    "run_multiprocess((0, 0))\n",
    "    \n",
    "_script += f'''\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = model.to(device)\n",
    "\n",
    "start_path = '{start_path}'\n",
    "NJOB={NJOB}\n",
    "meta = glob(start_path+'/wavs16k/*.wav')\n",
    "slice_len = (len(meta) + NJOB - 1) // NJOB\n",
    "meta = meta[int(sys.argv[1])*slice_len : (int(sys.argv[1])+1)*slice_len]\n",
    "\n",
    "for _dir in tqdm(meta):\n",
    "    audio, fs = sf.read(_dir)\n",
    "    assert fs == 16000\n",
    "    inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    for i in inputs:\n",
    "        inputs[i] = inputs[i].cuda()\n",
    "    with torch.no_grad():\n",
    "        hidden = model(**inputs, output_hidden_states=True)['hidden_states'][{LAYER} - 1]\n",
    "        hidden = F.layer_norm(hidden, hidden.shape)\n",
    "    np.save(_dir.replace(\"wavs16k\",\"feats\").replace(\".wav\",\"\"), hidden[0].cpu().numpy())\n",
    "\n",
    "print(\"Finish!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f292ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tmp(_script)\n",
    "res = pqdm(list(zip(cuda_devices, list(range(NJOB)))), run_multiprocess, n_jobs=NJOB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd99b9",
   "metadata": {},
   "source": [
    "###  Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basicly from: https://github.com/facebookresearch/fairseq/tree/main/examples/hubert/simple_kmeans\n",
    "# TODO: It seems pretty slow. Maybe try faiss or conduct PCA before clustering?\n",
    "\n",
    "os.makedirs(start_path + \"tmp\", exist_ok=True)\n",
    "os.makedirs(start_path + \"assets\", exist_ok=True)\n",
    "\n",
    "_script = f'''\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import joblib\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "params = {params}\n",
    "kmeans = MiniBatchKMeans(**params)\n",
    "\n",
    "start_path = '{start_path}'\n",
    "meta = glob(start_path+'/feats/*.npy')\n",
    "random.shuffle(meta)\n",
    "meta = meta[ : int(len(meta)*{percent})]\n",
    "meta = np.concatenate(\n",
    "    [np.load(i) for i in meta], axis = 0\n",
    ")\n",
    "print(\"concated.\")\n",
    "\n",
    "kmeans.fit(meta)\n",
    "joblib.dump(kmeans, start_path + \"assets/km_model.joblib\")\n",
    "\n",
    "inertia = -kmeans.score(meta) / len(meta)\n",
    "print(\"total intertia: %.5f\", inertia)\n",
    "print(\"Finish!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tmp(_script)\n",
    "\n",
    "# without thread limit, some error may occur.\n",
    "!echo OPENBLAS_NUM_THREADS=16 OMP_NUM_THREADS=16 python {start_path + '/tmp/temp.py'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9396094f",
   "metadata": {},
   "source": [
    "### Infer semantic indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(start_path + \"tmp\", exist_ok=True)\n",
    "os.makedirs(start_path + \"semantic_idx\", exist_ok=True)\n",
    "\n",
    "_script = f'''\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import joblib\n",
    "\n",
    "class ApplyKmeans(object):\n",
    "    def __init__(self, km_path):\n",
    "        self.km_model = joblib.load(km_path)\n",
    "        self.C_np = self.km_model.cluster_centers_.transpose()\n",
    "        self.Cnorm_np = (self.C_np ** 2).sum(0, keepdims=True)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        dist = (\n",
    "            (x ** 2).sum(1, keepdims=True)\n",
    "            - 2 * np.matmul(x, self.C_np)\n",
    "            + self.Cnorm_np\n",
    "        )\n",
    "        return np.argmin(dist, axis=1)\n",
    "        \n",
    "\n",
    "start_path = '{start_path}'\n",
    "NJOB={NJOB}\n",
    "meta = glob(start_path+'/feats/*.npy')\n",
    "slice_len = (len(meta) + NJOB - 1) // NJOB\n",
    "meta = meta[int(sys.argv[1])*slice_len : (int(sys.argv[1])+1)*slice_len]\n",
    "\n",
    "apply_kmeans = ApplyKmeans(start_path + '/assets/km_model.joblib')\n",
    "\n",
    "for _dir in tqdm(meta):\n",
    "    _idxs = apply_kmeans(np.load(_dir)).astype(np.int{dtype})\n",
    "    np.save(_dir.replace(\"feats\",\"semantic_idx\"), _idxs)\n",
    "    \n",
    "print(\"Finish!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d96be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tmp(_script)\n",
    "res = pqdm(list(zip(cuda_devices, list(range(NJOB)))), run_multiprocess, n_jobs=NJOB)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a05724",
   "metadata": {},
   "source": [
    "### Fetch discrete indices from encodec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(start_path + \"tmp\", exist_ok=True)\n",
    "os.makedirs(start_path + \"encodec_idx\", exist_ok=True)\n",
    "\n",
    "_script ='''\n",
    "from encodec import EncodecModel\n",
    "from encodec.utils import convert_audio\n",
    "\n",
    "model = EncodecModel.encodec_model_24khz()\n",
    "model.set_target_bandwidth(6.0)\n",
    "print(\"downloaded!\")\n",
    "'''\n",
    "write_tmp(_script) # download it.\n",
    "run_multiprocess((0, 0))\n",
    "    \n",
    "_script += f'''\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "device = 'cuda:0'\n",
    "model = model.to(device)\n",
    "\n",
    "start_path = '{start_path}'\n",
    "NJOB={NJOB}\n",
    "meta = glob(start_path+'/wavs/*.wav')\n",
    "slice_len = (len(meta) + NJOB - 1) // NJOB\n",
    "meta = meta[int(sys.argv[1])*slice_len : (int(sys.argv[1])+1)*slice_len]\n",
    "\n",
    "for _dir in tqdm(meta):\n",
    "    wav, sr = torchaudio.load(_dir)\n",
    "    wav = wav[:, :wav.shape[-1] - int(160*1.5)]\n",
    "    # wav = convert_audio(wav, sr, model.sample_rate, model.channels)\n",
    "    wav = wav.unsqueeze(0).cuda()\n",
    "    with torch.no_grad():\n",
    "        encoded_frames = model.encode(wav)[0][0][0]\n",
    "    np.save(_dir.replace(\"wavs\",\"encodec_idx\").replace(\".wav\",\"\"), encoded_frames.cpu().numpy().astype(np.int16))\n",
    "\n",
    "print(\"Finish!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5741ee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tmp(_script)\n",
    "res = pqdm(list(zip(cuda_devices, list(range(NJOB)))), run_multiprocess, n_jobs=NJOB)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b774eb",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf05fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_length = 2 # at least 2 seconds.\n",
    "# _min_length = int(np.floor(min_length * 50))\n",
    "for_eval = 128\n",
    "\n",
    "os.makedirs(start_path + \"meta\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb150c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "datas = pd.read_csv(start_path+\"meta/metadata.csv\",sep=\"|\", header=None)\n",
    "datas = datas.dropna()\n",
    "datas = datas.values\n",
    "np.random.shuffle(datas)\n",
    "\n",
    "with open(start_path + \"meta/train.json\",\"w\") as f:\n",
    "    for i in datas[:-for_eval]:\n",
    "        line = json.dumps({\"name\": i[0] +\".npy\", \"text\": i[1]})\n",
    "        f.writelines(line+\"\\n\")\n",
    "\n",
    "with open(start_path + \"meta/eval.json\",\"w\") as f:\n",
    "    for i in datas[-for_eval:]:\n",
    "        line = json.dumps({\"name\": i[0] +\".npy\", \"text\": i[1]})\n",
    "        f.writelines(line+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "181.663px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
