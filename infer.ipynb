{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5becc02",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f55af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import Audio\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "\n",
    "import barkify.bark as bark \n",
    "from barkify.utils import Bestckpt\n",
    "from barkify.bark import create_infer_model\n",
    "from barkify.datas import PhonemeTokenizer\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "x_dict =  OmegaConf.load(\"configs/barkify.yaml\")\n",
    "\n",
    "start_path = \"../work_env\" # your data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6dc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_INPUT_LEN = x_dict.stage1.collate_fn.text_window\n",
    "TEXT_TOKEN_NUM = x_dict.stage1.collate_fn.text_token_num\n",
    "SEMANTIC_EOS_TOKEN, SEMANTIC_INFER_TOKEN = TEXT_TOKEN_NUM+1, TEXT_TOKEN_NUM+2\n",
    "\n",
    "COARSE_BOOK = x_dict.stage2.collate_fn.Q_size\n",
    "SEMANTIC_TOKEN_NUM = x_dict.stage2.collate_fn.semantic_token_num\n",
    "SEMANTIC_INPUT_LEN = x_dict.stage2.collate_fn.semantic_window\n",
    "CODEC_TOKEN_NUM = x_dict.stage2.collate_fn.coarse_num\n",
    "COARSE_INFER_TOKEN = SEMANTIC_TOKEN_NUM + 1\n",
    "\n",
    "stage1_model = create_infer_model(x_dict.stage1.model).cuda()\n",
    "stage2_model = create_infer_model(x_dict.stage2.model).cuda()\n",
    "\n",
    "tokenizer = PhonemeTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(Bestckpt(f\"{start_path}/{x_dict.name}/stage_1\"))['state_dict']\n",
    "stage1_model.load_state_dict({\".\".join(i.split(\"model.\")[1:]):ckpt[i] for i in ckpt})\n",
    "\n",
    "ckpt = torch.load(Bestckpt(f\"{start_path}/{x_dict.name}/stage_2\"))['state_dict']\n",
    "stage2_model.load_state_dict({\".\".join(i.split(\"model.\")[1:]):ckpt[i] for i in ckpt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2e1bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stage1(\n",
    "    x, \n",
    "    model,\n",
    "    tempature = 0.60,\n",
    "    max_steps = 512,\n",
    "):\n",
    "\n",
    "    kv_cache = None\n",
    "\n",
    "    x = F.pad(x, (0, TEXT_INPUT_LEN-x.shape[1]), mode='constant', value=TEXT_TOKEN_NUM)\n",
    "    x = torch.cat([\n",
    "        x, \n",
    "        torch.tensor([SEMANTIC_INFER_TOKEN], dtype=x.dtype, device=x.device)[None]\n",
    "    ], dim=1)\n",
    "    \n",
    "    text_len = x.shape[1]\n",
    "\n",
    "    for _ in tqdm.trange(max_steps):\n",
    "        \n",
    "        if kv_cache is not None:\n",
    "            x_input = x[:, [-1]]\n",
    "        else:\n",
    "            x_input = x\n",
    "\n",
    "        logits, kv_cache = model(x_input, use_cache=True, past_kv=kv_cache)\n",
    "\n",
    "        relevant_logits = torch.hstack(\n",
    "            (logits[0, 0, TEXT_TOKEN_NUM+3:], logits[0, 0, [SEMANTIC_EOS_TOKEN]])\n",
    "        )\n",
    "\n",
    "        probs = F.softmax(relevant_logits / tempature, dim=-1)\n",
    "        item_next = torch.multinomial(probs, num_samples=1)\n",
    "\n",
    "        if item_next == len(relevant_logits) - 1:\n",
    "            break\n",
    "\n",
    "        x = torch.cat((x, item_next[None]+TEXT_TOKEN_NUM+3), dim=1)\n",
    "    \n",
    "    return x[:, text_len:] - TEXT_TOKEN_NUM - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f9642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stage2(\n",
    "    x, \n",
    "    model,\n",
    "    tempature = 0.6,\n",
    "    max_steps = 768\n",
    "):\n",
    "\n",
    "    kv_cache = None\n",
    "    \n",
    "    x = F.pad(x, (0, SEMANTIC_INPUT_LEN-x.shape[1]), mode='constant', value=SEMANTIC_TOKEN_NUM)\n",
    "    x = torch.cat([\n",
    "        x, \n",
    "        torch.tensor([COARSE_INFER_TOKEN], dtype=x.dtype, device=x.device)[None]\n",
    "    ], dim=1)\n",
    "    \n",
    "    semantic_len = x.shape[1]\n",
    "\n",
    "    for i in tqdm.trange(max_steps):\n",
    "\n",
    "        Q = i % COARSE_BOOK\n",
    "        if kv_cache is not None:\n",
    "            x_input = x[:, [-1]]\n",
    "        else:\n",
    "            x_input = x\n",
    "\n",
    "        logits, kv_cache = model(x_input, use_cache=True, past_kv=kv_cache)\n",
    "        start = SEMANTIC_TOKEN_NUM + 2 + Q * CODEC_TOKEN_NUM\n",
    "        relevant_logits = logits[0, 0, start : start + CODEC_TOKEN_NUM]\n",
    "        \n",
    "        probs = F.softmax(relevant_logits / tempature, dim=-1)\n",
    "        item_next = torch.multinomial(probs, num_samples=1)\n",
    "        x = torch.cat((x, item_next[None]+start), dim=1)\n",
    "    \n",
    "    output = x[:, semantic_len:]\n",
    "    for Q in range(COARSE_BOOK):\n",
    "        output[:, Q::COARSE_BOOK] -= (SEMANTIC_TOKEN_NUM + 2 + Q * CODEC_TOKEN_NUM)\n",
    "    \n",
    "    return output.reshape(-1, COARSE_BOOK).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_text = \"At a given signal, they reenacted the event. Baker's movements were timed with a stopwatch.\"\n",
    "\n",
    "tokens = tokenizer(tgt_text)\n",
    "dummy_tokenized = torch.tensor([tokens]).cuda()\n",
    "dummy_semantic = generate_stage1(dummy_tokenized, model=stage1_model)\n",
    "dummy_coarse = generate_stage2(dummy_semantic, model=stage2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499e142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_fine = bark.generate_fine(dummy_coarse.detach().cpu().numpy(), history_prompt=None)\n",
    "audio_array = bark.codec_decode(dummy_fine)\n",
    "\n",
    "# play text in notebook\n",
    "Audio(audio_array, rate=24000)\n",
    "\n",
    "# write_wav(\"bark_generation.wav\", 24000, audio_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
